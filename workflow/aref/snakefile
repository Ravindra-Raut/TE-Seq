container: "docker://maxfieldkelsey/pipelinerteseq:v0.5"
import os
import pandas as pd
import csv
from pathlib import Path
from pandas.core.common import flatten

sample_table = pd.read_csv("conf/sample_table_aref.csv")

def aref_complete_input(wildcards):
    final_input = []
    if config["symlink_aref_contents"]["response"] == "yes":
        final_input.append("aref_contents.symlinked.outfile")
        return final_input
    paths = [
        "aref/A.REF_annotations/A.REF_repeatmasker.complete.gff3.gz.tbi",
        "aref/A.REF_annotations/refseq.complete.gff3.gz.tbi",
        "aref/A.REF_annotations/A.REF_repeatmasker.complete.gtf.gz.tbi",
        "aref/A.REF_annotations/refseq.complete.gtf.gz.tbi",
        "aref/A.REF_annotations/A.REF_repeatmasker_refseq.complete.gtf",
        "aref/A.REF_annotations/A.REF_repeatmasker_refseq.complete.gff3",
        "aref/A.REF_annotations/A.REF_repeatmasker.complete.bed",
        "aref/A.REF_annotations/A.REF_rte_beds/outfile.txt",
        "aref/A.REF_annotations/A.REF_repeatmasker_refseq.complete.sqlite",
        "aref/A.REF_annotations/cytobands.bed",
        "aref/A.REF_Analysis/l1element_analysis.rds"
    ]
    # paths.append(expand("aref/{sample_or_ref}_Analysis/l1element_analysis.outfile", sample_or_ref = "A.REF"))

    if config["update_ref_with_tldr"]["response"] == "yes":
        paths.append(expand("aref/qc/{sample_or_ref}/{sample_or_ref}pycoQC.html", sample_or_ref = config["samples"]))
        paths.append("aref/results/insertions/analyze_nongermline_insertions.rds")

        if config["update_ref_with_tldr"]["per_sample"] == "yes":
            paths.append(expand("aref/{sample_or_ref}_Analysis/tldr_plots/tldr_plots.rds", sample_or_ref = config["samples"]))
            paths.append(expand("aref/{sample_or_ref}_Analysis/tldr_plots/transduction_mapping.rds", sample_or_ref = config["samples"]))
            paths.append(expand("aref/{sample_or_ref}_Analysis/l1element_analysis.rds", sample_or_ref = config["samples"]))
            paths.append(expand("aref/{sample_or_ref}_annotations/{sample_or_ref}_rte_beds/outfile.txt", sample_or_ref = config["samples"]))
            paths.append(expand("aref/{sample_or_ref}_tldr/{sample_or_ref}.table.txt", sample_or_ref = config["samples"]))
            
            # paths.append(expand("aref/{sample_or_ref}_Analysis/l1element_analysis.outfile", sample_or_ref = "A.REF"))
            paths.append(expand("aref/{sample_or_ref}_annotations/{sample_or_ref}_rte_beds/outfile.txt", sample_or_ref = config["samples"]))
            paths.append(expand("aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_refseq.complete.gtf", sample_or_ref = config["samples"]))
            paths.append(expand("aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_refseq.gff3", sample_or_ref = config["samples"]))
            paths.append(expand("aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_refseq.complete.gff3", sample_or_ref = config["samples"]))
            paths.append(expand("aref/{sample_or_ref}_indeces/make_star_index.out", sample_or_ref = config["samples"]))

        else:
            paths.append(expand("aref/{sample_or_ref}_Analysis/tldr_plots/tldr_plots.rds", sample_or_ref = "A.REF"))
            paths.append(expand("aref/{sample_or_ref}_Analysis/tldr_plots/transduction_mapping.rds", sample_or_ref = "A.REF"))
            paths.append(expand("aref/{sample_or_ref}_annotations/{sample_or_ref}_rte_beds/outfile.txt", sample_or_ref = "A.REF"))
            paths.append(expand("aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_refseq.complete.gtf", sample_or_ref = "A.REF"))
            paths.append(expand("aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_refseq.gff3", sample_or_ref = "A.REF"))
            paths.append(expand("aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_refseq.complete.gff3", sample_or_ref = "A.REF"))
            paths.append(expand("aref/{sample_or_ref}_indeces/make_star_index.out", sample_or_ref = "A.REF"))

    else:
        paths.append("aref/A.REF_indeces/make_star_index.out")


    if config["running_ldna"]["response"] == "yes":
        paths.append("aref/A.REF_annotations/cpg_islands.bed")
    
    for path in list(flatten(paths)):
        final_input.append(path)
    print(final_input)
    return final_input


#tag FILESTRUCTURE
paths = [
    "aref/benchmarks",
    ]
for path in paths:
    os.makedirs(path, exist_ok = True)


rule aref_complete:
    input: aref_complete_input
    output: ancient("aref.done.outfile")
    shell: "touch {output}"
rule sym_link:
    input:
        aref_dir = config["symlink_aref"]["aref_symlinkdir"]
    output:
        ancient("aref.done.outfile")
    shell:
        """
ln -s {input.aref_dir} aref
touch {output}
        """
rule sym_link_aref_contents:
    input:
        aref_dir = config["symlink_aref"]["aref_symlinkdir"]
    output:
        sym_link_outfile = "aref_contents.symlinked.outfile"
    shell:
        """
ln -s {input.aref_dir}/* aref/
touch {output.sym_link_outfile}
        """

#tag BASECALLING
rule dorado:
    input:
        dir = lambda wildcards: sample_table.loc[sample_table["sample_name"] == wildcards.sample, "nanopore_rawdata_dir"].iloc[0]
    output:
        calls = "aref/intermediates/{sample}/alignments/{rate}/{sample}.{type}.{modifications_string}.bam"
    wildcard_constraints:
        sample="[0-9A-Za-z_]+",
        type = "[0-9A-Za-z]+",
        rate = "[0-9A-Za-z]+",
        modifications_string = "[0-9A-Za-z_-]+"
    container: None
    benchmark:
        "aref/benchmarks/dorado/{rate}.{sample}.{type}.{modifications_string}.tsv"
    params:
        dorado = config["dorado"],
        reference = config["update_ref_with_tldr"]["tldr_input_bam_ref"]
    resources:
        cpus_per_task =12,
        slurm_partition="gpu-he",
        mem_mb = 128000,
        slurm_extra="--time=96:00:00 --prefer=a6000 --gres=gpu:2"
    shell:
        """
mkdir -p $(dirname {output.calls})
mod_string=$(echo {wildcards.modifications_string} | tr "-" ",")

{params.dorado} \
basecaller \
{wildcards.type},$mod_string \
{input.dir} \
--recursive \
--verbose \
--reference {params.reference} > {output.calls}.unfinished
mv {output.calls}.unfinished {output.calls}
        """

rule call_dorado_resume:
    input:
        expand("aref/intermediates/{sample}/alignments/{rate}/{sample}.{type}.{modifications_string}.bam.unfinished", sample = config["samples"], rate = config["rate"], type = config["type"], modifications_string = config["modification_string"])

rule dorado_resume:
    input:
        unfinished = "aref/intermediates/{sample}/alignments/{rate}/{sample}.{type}.{modifications_string}.bam.unfinished"
    output:
        calls = "aref/intermediates/{sample}/alignments/{rate}/{sample}.{type}.{modifications_string}.bam.finished"
    benchmark:
        "aref/benchmarks/dorado_resume/{rate}.{sample}.{type}.{modifications_string}.tsv"
    wildcard_constraints:
        sample="[0-9A-Za-z_]+",
        type = "[0-9A-Za-z]+",
        rate = "[0-9A-Za-z]+",
        modifications_string = "[0-9A-Za-z_-]+"
    params:
        dorado = config["dorado"],
        basecallingModel = lambda w: config["basecallingModel"][w.rate][w.type],
        reference = config["update_ref_with_tldr"]["tldr_input_bam_ref"]
    resources:
        cpus_per_task =12,
        slurm_partition="gpu-he",
        mem_mb = 128000,
        slurm_extra="--time=48:00:00 --prefer=a6000 --gres=gpu:2"
    shell:
        """
mkdir -p $(dirname {output.calls})
mod_string=$(echo {wildcards.modifications_string} | tr "-" ",")

{params.dorado} \
basecaller \
{wildcards.type},$mod_string \
{input.dir} \
--resume-from {input.unfinished} \
--recursive \
--verbose \
--reference {params.reference} > {output.calls}.temp
mv {output.calls}.temp {output.calls}
        """



rule dorado_seqsummary:
    input:
        sortedbam = expand("aref/intermediates/{{sample}}/alignments/{rate}/{{sample}}.{type}.{modification_string}.sorted.bam", rate = config["rate"], type = config["type"], modification_string = config["modification_string"]),
        sortedbamindex = expand("aref/intermediates/{{sample}}/alignments/{rate}/{{sample}}.{type}.{modification_string}.sorted.bam.bai", rate = config["rate"], type = config["type"], modification_string = config["modification_string"]),
    params:
        dorado = config["dorado"]
    benchmark:
        "aref/benchmarks/dorado_seqsummary/{sample}.tsv"
    output:
        "aref/qc/{sample}/{sample}.doradosummary.txt"
    conda:
        "omics"
    shell:
        """
{params.dorado} summary {input.sortedbam} > {output}
        """

rule pycoQC:
    input:
        seqsummary = "aref/qc/{sample}/{sample}.doradosummary.txt",
        sortedbam = expand("aref/intermediates/{{sample}}/alignments/{rate}/{{sample}}.{type}.{modification_string}.sorted.bam", rate = config["rate"], type = config["type"], modification_string = config["modification_string"]),
    output:
        html = "aref/qc/{sample}/{sample}pycoQC.html",
        json = "aref/qc/{sample}/{sample}pycoQC.json"
    benchmark:
        "aref/benchmarks/pycoQC/{sample}.tsv"
    resources:
        mem_mb = 100000,
    conda:
        "pycoQC"
    shell:
        """
mkdir -p $(dirname {output})
pycoQC --summary_file {input.seqsummary} --bam_file {input.sortedbam} --html_outfile {output.html} --json_outfile {output.json} --min_pass_qual 10
        """

#tag ALIGNMENT_UTILITIES
rule subsample_bam:
    input:
        bam = "aref/intermediates/{sample}/alignments/{rate}/{sample}.{type}.{modifications_string}.bam"
    output:
        subsampled = "aref/intermediates/{sample}/alignments/{rate}/{sample}.{type}.{modifications_string}.subsampled.bam"
    benchmark:
        "aref/benchmarks/subsample_bam/{rate}.{sample}.{type}.{modifications_string}.tsv"
    resources:
        cpus_per_task =10,
        mem_mb = 64000
    conda:
        "omics"
    shell:
        """
mkdir -p $(dirname {output.subsampled})

samtools view -b {input.bam} chr10 > {output.subsampled}
        """

ruleorder: merge_bams_when_per_sample_is_no_for_ldna_variants > sortBam 
rule merge_bams_when_per_sample_is_no_for_ldna_variants:
    input:
        sorted_bams = expand("aref/intermediates/{sample}/alignments/{{rate}}/{sample}.{{type}}.{{modifications_string}}.sorted.bam", sample = config["samples"])
    output:
        merged_bams = "aref/intermediates/A.REF/alignments/{rate}/A.REF.{type}.{modifications_string}.sorted.bam"
    benchmark:
        "aref/benchmarks/sortBam/{rate}.{type}.{modifications_string}.tsv"
    wildcard_constraints:
        modifications_string = "[A-Za-z0-9_-]+"
    resources:
        cpus_per_task =10,
        mem_mb = 128000
    conda:
        "omics"
    shell:
        """
mkdir -p $(dirname {output})
samtools merge -@8 {output.merged_bams} {input.sorted_bams}
        """

rule sortBam:
    input:
        bam = "aref/intermediates/{sample}/alignments/{rate}/{sample}.{type}.{modifications_string}.bam"
    output:
        sortedbam = "aref/intermediates/{sample}/alignments/{rate}/{sample}.{type}.{modifications_string}.sorted.bam"
    benchmark:
        "aref/benchmarks/sortBam/{rate}.{sample}.{type}.{modifications_string}.tsv"
    wildcard_constraints:
        modifications_string = "[A-Za-z0-9_-]+"
    resources:
        cpus_per_task =10,
        mem_mb = 64000
    conda:
        "omics"
    shell:
        """
mkdir -p $(dirname {output})
samtools sort -@8 -m4g {input.bam} > {output.sortedbam}
        """

rule IndexBam:
    input:
        bam = "aref/{bampath}.bam"
    output:
        index = "aref/{bampath}.bam.bai"
    benchmark:
        "aref/benchmarks/IndexBam/{bampath}.tsv"
    resources:
        cpus_per_task =10,
        mem_mb = 64000
    conda:
        "omics"
    shell:
        """
samtools index  -@6 {input.bam}
        """
        
species = config["species"]
rule tldr_aggregate_multiple_samples:
    input:
        bams = expand("aref/intermediates/{sample}/alignments/{rate}/{sample}.{type}.{modification_string}.sorted.bam", sample = config["samples"], rate = config["rate"], type = config["type"], modification_string = config["modification_string"]),
        bais = expand("aref/intermediates/{sample}/alignments/{rate}/{sample}.{type}.{modification_string}.sorted.bam.bai", sample = config["samples"], rate = config["rate"], type = config["type"], modification_string = config["modification_string"]),
    params:
        tldr_input_bam_ref = lambda w: config["update_ref_with_tldr"]["tldr_input_bam_ref"],
        tldr_te_ref = lambda w: config["update_ref_with_tldr"]["tldr_te_ref"][species]
    benchmark:
        "aref/benchmarks/tldr_aggregate_multiple_samples/tldr_aggregate_multiple_samples.tsv"
    output:
        tldr = "aref/A.REF_tldr/A.REF.table.txt"
    resources:
        cpus_per_task = 24,
        mem_mb = 100000,
        runtime = 300
    conda:
        "tldr"
    shell:
        """
bams=$(echo {input.bams})
commabams=$(echo $bams | tr ' ' ',')

tldr -b $commabams \
-e {params.tldr_te_ref} \
-r {params.tldr_input_bam_ref} \
-p 20 \
--minreads 1 \
--outbase A.REF \
--detail_output \
--extend_consensus 4000 \
--trdcol

mkdir -p $(dirname {output.tldr})
mv A.REF.table.txt {output.tldr}
mv A.REF $(dirname {output.tldr})/
        """

rule call_tldr_per_sample:
    input:
        expand("aref/{sample_or_ref}_tldr/{sample_or_ref}.table.txt", sample = config["samples"], sample_or_ref = config["samples"])
rule tldr_per_sample:
    input:
        bam = expand("aref/intermediates/{{sample}}/alignments/{rate}/{{sample}}.{type}.{modification_string}.sorted.bam", rate = config["rate"], type = config["type"], modification_string = config["modification_string"]),
        bai = expand("aref/intermediates/{{sample}}/alignments/{rate}/{{sample}}.{type}.{modification_string}.sorted.bam.bai", rate = config["rate"], type = config["type"], modification_string = config["modification_string"])
    benchmark:
        "aref/benchmarks/tldr_per_sample/{sample}.tsv"
    params:
        tldr_input_bam_ref = lambda w: config["update_ref_with_tldr"]["tldr_input_bam_ref"],
        tldr_te_ref = lambda w: config["update_ref_with_tldr"]["tldr_te_ref"][species]
    output:
        tldr = "aref/{sample}_tldr/{sample}.table.txt"
    resources:
        cpus_per_task = 24,
        mem_mb = 100000,
        runtime = 300
    conda:
        "tldr"
    shell:
        """
tldr -b {input.bam} \
-e {params.tldr_te_ref} \
-r {params.tldr_input_bam_ref} \
-p 20 \
--minreads 1 \
--outbase {wildcards.sample} \
--detail_output \
--extend_consensus 4000 \
--trdcol

mkdir -p $(dirname {output.tldr})
mv {wildcards.sample}.table.txt {output.tldr}
mv {wildcards.sample} $(dirname {output.tldr})/
        """

rule update_reference:
    input:
        reference = lambda w: config["update_ref_with_tldr"]["tldr_input_bam_ref"],
        tldroutput = "aref/{sample_or_ref}_tldr/{sample_or_ref}.table.txt"
    output:
        updated_reference = "aref/{sample_or_ref}-pre-ins-filtering.fa",
        non_ref_contigs = "aref/{sample_or_ref}-pre-ins-filtering_nonrefcontigs.fa"
    benchmark:
        "aref/benchmarks/update_reference/{sample_or_ref}.tsv"
    conda:
        "repeatanalysis"
    script:
        "scripts/create_reference.R"


rule move_starting_reference:
    params:
        ref = config["starting_ref"]
    output:
        ref = "aref/A.REF.fa"
    shell:
        """
cp {params.ref} {output.ref}
        """

rule get_repeatmasker_raw:
    params:
        repeatmasker = config["starting_ref_repeatmasker"]
    output:
        repeatmasker = "aref/{sample_or_ref}_repeatmasker/A.REF_repeatmasker_raw.gtf"
    benchmark:
        "aref/benchmarks/get_repeatmasker_raw/{sample_or_ref}.tsv"
    shell:
        """
cp {params.repeatmasker} {output.repeatmasker}
workflow/aref/scripts/outToGtf.sh {params.repeatmasker} {output.repeatmasker}
        """

rule index_reference:
    input:
        reference = "aref/{sample_or_ref}.fa"
    output:
        reference_index = "aref/{sample_or_ref}.fa.fai"
    benchmark:
        "aref/benchmarks/index_reference/{sample_or_ref}.tsv"
    conda:
        "omics"
    shell:
        """
samtools faidx {input.reference}
        """


def repeatmasker_input(wildcards):
    if config["update_ref_with_tldr"]["response"] == "yes":
        return expand("aref/{sample_or_ref}-pre-ins-filtering_nonrefcontigs.fa", sample_or_ref = wildcards.sample_or_ref)
    else:
        return config["ref"]

rule repeatmasker:
    input:
        fasta = repeatmasker_input
    params:
        species = config["species"]
    benchmark:
        "aref/benchmarks/repeatmasker/{sample_or_ref}.tsv"
    output:
        rmout = "aref/A.REF_repeatmasker/{sample_or_ref}-pre-ins-filtering_nonrefcontigs.fa.out"
    resources:
        cpus_per_task =20,
        runtime = 1200,
        mem_mb = 50000
    container: "docker://dfam/tetools:latest"
    shell:
        """
if [[ {params.species} == mouse ]]
then
species="Mus musculus"
else
species={params.species}
fi
mkdir -p $(dirname {output})
RepeatMasker -species "$species" -pa {resources.cpus_per_task} -gff {input.fasta} -dir $(dirname {output})
        """

rule getGtfs:
    input:
        rmout = "aref/A.REF_repeatmasker/{sample_or_ref}-pre-ins-filtering_nonrefcontigs.fa.out",
    params:
        rmref = config["starting_ref_repeatmasker"],
        module_prefix = config["prefix"]
    benchmark:
        "aref/benchmarks/getGtfs/{sample_or_ref}.tsv"
    output:
       ref = "aref/A.REF_repeatmasker/{sample_or_ref}_repeatmasker_ref_raw.gtf",
       nonref = "aref/A.REF_repeatmasker/{sample_or_ref}_repeatmasker_nonref_raw.gtf",
       merged = "aref/A.REF_repeatmasker/{sample_or_ref}_repeatmasker_raw.gtf"
    conda:
        "evo2"
    shell:
        """
workflow/{params.module_prefix}/scripts/outToGtf.sh {input.rmout} {output.nonref}
workflow/{params.module_prefix}/scripts/outToGtf.sh {params.rmref} {output.ref}
cat {output.ref} {output.nonref} > {output.merged}
        """

rule process_gtf:
    input:
        gtf = "aref/A.REF_repeatmasker/A.REF_repeatmasker_raw.gtf",
        ref_cytobands = "aref/A.REF_annotations/cytobands.bed",
        ref = "aref/A.REF.fa"
    output:
        repmask_gff2 = "aref/A.REF_annotations/A.REF_repeatmasker.gff2",
        repmask_gff3 = "aref/A.REF_annotations/A.REF_repeatmasker.gff3",
        r_annotation_fragmentsjoined = "aref/A.REF_annotations/A.REF_repeatmasker.gtf.rformatted.fragmentsjoined.csv"
    benchmark:
        "aref/benchmarks/process_gtf/process_gtf.tsv"
    conda:
        "evo2"
    script:
        "scripts/process_gtf.R"

rule process_gtf_tldr:
    input:
        gtf = "aref/A.REF_repeatmasker/{sample_or_ref}_repeatmasker_raw.gtf",
        ref_cytobands = "aref/A.REF_annotations/cytobands.bed",
        ref = "aref/{sample_or_ref}-pre-ins-filtering.fa",
        tldroutput = "aref/{sample_or_ref}_tldr/{sample_or_ref}.table.txt"
    output:
        contigs_to_keep = "aref/{sample_or_ref}_contigs_to_keep.txt",
        filtered_tldr = "aref/{sample_or_ref}_tldr/{sample_or_ref}.table.kept_in_updated_ref.txt",
        repmask_gff2 = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker.gff2",
        repmask_gff3 = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker.gff3",
        r_annotation_fragmentsjoined = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker.gtf.rformatted.fragmentsjoined.csv"
    benchmark:
        "aref/benchmarks/process_gtf_tldr/{sample_or_ref}.tsv"
    conda:
        "evo2"
    script:
        "scripts/process_gtf_tldr.R"

rule analyze_insertions:
    input:
        tldroutput = "aref/{sample_or_ref}_tldr/{sample_or_ref}.table.txt",
        filtered_tldr = "aref/{sample_or_ref}_tldr/{sample_or_ref}.table.kept_in_updated_ref.txt",
        r_annotation_fragmentsjoined = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker.gtf.rformatted.fragmentsjoined.csv",
        r_repeatmasker_annotation = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_annotation.csv",
        ref = "aref/{sample_or_ref}-pre-ins-filtering.fa",
        element_analysis = "aref/{sample_or_ref}_Analysis/l1element_analysis.rds"
    output:
        plots = "aref/{sample_or_ref}_Analysis/tldr_plots/tldr_plots.rds",
    benchmark:
        "aref/benchmarks/analyze_insertions/{sample_or_ref}.tsv"
    conda:
        "evo2"
    script:
        "scripts/analyze_insertions.R"

rule analyze_nongermline_insertions:
    input:
        json = expand("aref/qc/{sample}/{sample}pycoQC.json", sample = config["samples"]),
        tldroutput = lambda w: expand("aref/{sample}_tldr/{sample}.table.txt", sample = config["samples"]) if config["update_ref_with_tldr"]["per_sample"] == "yes" else "aref/A.REF_tldr/A.REF.table.txt"
    output:
        plots = "aref/results/insertions/analyze_nongermline_insertions.rds"
    benchmark:
        "aref/benchmarks/analyze_nongermline_insertions/analyze_nongermline_insertions.tsv"
    conda:
        "ds"
    script:
        "scripts/analyze_nongermline_insertions.R"
        
rule cleanup_updated_ref:
    input:
        updated_reference = "aref/A.REF-pre-ins-filtering.fa",
        contigs_to_keep = "aref/A.REF_contigs_to_keep.txt"
    output:
        filtered_ref = "aref/A.REF.fa"
    benchmark:
        "aref/benchmarks/cleanup_updated_ref/cleanup_updated_ref.tsv"
    conda:
        "omics"
    shell:
        """
seqkit grep --by-name -f {input.contigs_to_keep} {input.updated_reference} > {output.filtered_ref}
samtools faidx {output.filtered_ref}
        """

rule cleanup_updated_sample_ref:
    input:
        updated_reference = "aref/{sample}-pre-ins-filtering.fa",
        contigs_to_keep = "aref/{sample}_contigs_to_keep.txt"
    output:
        filtered_ref = "aref/{sample}.fa"
    benchmark:
        "aref/benchmarks/cleanup_updated_sample_ref/{sample}.tsv"
    wildcard_constraints:
        sample = "[A-Za-z0-9_]+"
    conda:
        "omics"
    shell:
        """
seqkit grep --by-name -f {input.contigs_to_keep} {input.updated_reference} > {output.filtered_ref}
samtools faidx {output.filtered_ref}
        """

rule move_refseq:
    input:
        ref_refseq_gff3 = config["ref_refseq_gff3"],
        ref_refseq_gtf = config["ref_refseq_gtf"]
    output:
        refseq_gff3 = "aref/{sample_or_ref}_annotations/refseq.possibly_unsorted.gff3",
        refseq_gtf = "aref/{sample_or_ref}_annotations/refseq.possibly_unsorted.gtf"
    benchmark:
        "aref/benchmarks/move_refseq/{sample_or_ref}.tsv"
    shell:
        """
cp {input.ref_refseq_gff3} {output.refseq_gff3}
cp {input.ref_refseq_gtf} {output.refseq_gtf}
        """

rule sort_refseq_get_bed:
    input:
        refseq_gff3 = "aref/{sample_or_ref}_annotations/refseq.possibly_unsorted.gff3",
        refseq_gtf = "aref/{sample_or_ref}_annotations/refseq.possibly_unsorted.gtf"
    output:
        refseq_gff3 = "aref/{sample_or_ref}_annotations/refseq.gff3",
        refseq_gtf = "aref/{sample_or_ref}_annotations/refseq.gtf",
        refseq_bed = "aref/{sample_or_ref}_annotations/refseq.bed"
    benchmark:
        "aref/benchmarks/sort_refseq_get_bed/{sample_or_ref}.tsv"
    conda:
        "omics"
    shell:
        """
awk '!/#/ {{print}}' {input.refseq_gff3} | sort -k1,1V -k4,4n -k5,5n > {output.refseq_gff3}
awk '!/#/ {{print}}' {input.refseq_gtf} | sort -k1,1V -k4,4n -k5,5n > {output.refseq_gtf}
gtf2bed < {output.refseq_gtf} > {output.refseq_bed}
        """

rule complete_gff3:
    input:
        gff3 = "aref/{sample_or_ref}_annotations/{annotation}.gff3",
    output:
        complete_gff3 = "aref/{sample_or_ref}_annotations/{annotation}.complete.gff3",
    benchmark:
        "aref/benchmarks/complete_gff3/{sample_or_ref}.{annotation}.tsv"
    resources:
        mem_mb = 128000,
        runtime = 300
    conda:
        "omics"
    shell:
        """
rm -f {output.complete_gff3}.temp
agat_convert_sp_gxf2gxf.pl --gff {input.gff3} -o {output.complete_gff3}.temp
awk '!/#/ {{print}}' {output.complete_gff3}.temp | awk '{{FS="\t";OFS="\t"}} $4 < 900000000000 {{print}}' | sort -k1,1V -k4,4n -k5,5n > {output.complete_gff3}
rm  {output.complete_gff3}.temp
        """


rule gff_to_gtf:
    input:
        complete_gff3 = "aref/{sample_or_ref}_annotations/{annotation}.complete.gff3",
    output:
        gtf = "aref/{sample_or_ref}_annotations/{annotation}.complete.gtf",
    benchmark:
        "aref/benchmarks/gff_to_gtf/{sample_or_ref}.{annotation}.tsv"
    conda:
        "omics"
    resources:
        mem_mb = 128000,
        runtime = 300
    shell:
        """
rm -f {output.gtf}.temp
agat_convert_sp_gff2gtf.pl --gff {input.complete_gff3} -o {output.gtf}.temp
awk '!/#/ {{print}}' {output.gtf}.temp | awk '{{FS="\t";OFS="\t"}} $4 < 900000000000 {{print}}' | sort -k1,1V -k4,4n -k5,5n > {output.gtf}
rm {output.gtf}.temp
        """

rule gff_to_bed12:
    input:
        complete_gff3 = "aref/{sample_or_ref}_annotations/{annotation}.complete.gff3",
    output:
        bed12 = "aref/{sample_or_ref}_annotations/{annotation}.complete.bed"
    benchmark:
        "aref/benchmarks/gff_to_bed12/{sample_or_ref}.{annotation}.tsv"
    resources:
        mem_mb = 128000,
        runtime = 300
    conda:
        "omics"
    shell:
        """
rm -f {output.bed12}.temp
agat_convert_sp_gff2bed.pl --gff {input.complete_gff3} -o {output.bed12}.temp
awk '!/#/ {{print}}' {output.bed12}.temp | awk '{{FS="\t";OFS="\t"}} $4 < 900000000000 {{print}}' | sort -k1,1V -k2,2n -k3,3n > {output.bed12}
rm {output.bed12}.temp
        """

ruleorder: merge_genes_and_repeats_gff > complete_gff3 
rule merge_genes_and_repeats_gff:
    input:
        complete_repeat_gff3 = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker.complete.gff3",
        complete_refseq_gff3 = "aref/A.REF_annotations/refseq.complete.gff3"
    output:
        merged_gff3 = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_refseq.complete.gff3"
    benchmark:
        "aref/benchmarks/merge_genes_and_repeats_gff/{sample_or_ref}.tsv"
    resources:
        mem_mb = 128000,
        runtime = 600
    conda:
        "omics"
    shell:
        """
rm -f {output.merged_gff3}.temp
agat_sp_merge_annotations.pl -f {input.complete_refseq_gff3} -f {input.complete_repeat_gff3} -o {output.merged_gff3}.temp
awk '!/#/ {{print}}' {output.merged_gff3}.temp | awk '{{FS="\t";OFS="\t"}} $4 < 900000000000 {{print}}' | sort -k1,1V -k4,4n -k5,5n >  {output.merged_gff3}
rm {output.merged_gff3}.temp
        """

rule merge_OG_genes_and_repeats_gff3:
    input:
        repeatmasker = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker.gff3",
        refseq = "aref/A.REF_annotations/refseq.gff3"
    output:
        merged_gff3 = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_refseq.gff3"
    benchmark:
        "aref/benchmarks/merge_OG_genes_and_repeats_gff3/{sample_or_ref}.tsv"
    resources:
        mem_mb = 128000,
        runtime = 300
    conda:
        "omics"
    shell:
        """
rm -f {output.merged_gff3}.temp
awk '!/#/ {{print}}' {input.repeatmasker} | awk '{{FS="\t";OFS="\t"}} $4 < 900000000000 {{print}}' > {output.merged_gff3}.temp
awk '!/#/ {{print}}' {input.refseq} | awk '{{FS="\t";OFS="\t"}} $4 < 900000000000 {{print}}' >> {output.merged_gff3}.temp
cat {output.merged_gff3}.temp | sort -k1,1V -k4,4n -k5,5n > {output.merged_gff3}
rm {output.merged_gff3}.temp
        """

ruleorder: merge_genes_and_repeats_gtf > gff_to_gtf 

rule merge_genes_and_repeats_gtf:
    input:
        complete_repeat_gtf = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker.complete.gtf",
        complete_refseq_gtf = "aref/A.REF_annotations/refseq.complete.gtf"
    output:
        merged_gtf = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_refseq.complete.gtf"
    benchmark:
        "aref/benchmarks/merge_genes_and_repeats_gtf/{sample_or_ref}.tsv"
    resources:
        mem_mb = 128000,
        runtime = 600
    conda:
        "omics"
    shell:
        """
rm -f {output.merged_gtf}.temp
agat_sp_merge_annotations.pl -f {input.complete_refseq_gtf} -f {input.complete_repeat_gtf} -o {output.merged_gtf}.temp
awk '!/#/ {{print}}' {output.merged_gtf}.temp | awk '{{FS="\t";OFS="\t"}} $4 < 900000000000 {{print}}' | sort -k1,1V -k4,4n -k5,5n > {output.merged_gtf}
rm {output.merged_gtf}.temp
        """

rule tabixindex:
    input:
        annot = "aref/{sample_or_ref}_annotations/{annot}"
    output:
        gz = "aref/{sample_or_ref}_annotations/{annot}.gz",
        index = "aref/{sample_or_ref}_annotations/{annot}.gz.tbi"
    benchmark:
        "aref/benchmarks/tabixindex/{sample_or_ref}.{annot}.tsv"
    resources:
        mem_mb = 60000,
        runtime = 300
    conda:
        "omics"
    shell:
        """

awk '!/#/ {{print}}' {input.annot} | sort -k1,1V -k4,4n -k5,5n -t '\t'| bgzip > {input.annot}.gz
tabix -p gff {input.annot}.gz
        """

rule get2bitgenome:
    input:
        ref = "aref/A.REF.fa"
    output:
        genome2bit = "aref/A.REF.2bit"
    benchmark:
        "aref/benchmarks/get2bitgenome/get2bitgenome.tsv"
    conda:
        "omics"
    shell:
        """
faToTwoBit {input.ref} {output.genome2bit}
        """


rule makeTxDB:
    input:
        refseq = "aref/A.REF_annotations/refseq.gff3",
        repeatmasker = "aref/A.REF_annotations/A.REF_repeatmasker.complete.gff3",
        genome2bit = "aref/A.REF.2bit"
    output:
        txdb = "aref/A.REF_annotations/A.REF_repeatmasker_refseq.complete.sqlite",
        txdbrefseq = "aref/A.REF_annotations/refseq.sqlite",
        txdbrepeatmasker = "aref/A.REF_annotations/A.REF_repeatmasker.complete.sqlite"
    benchmark:
        "aref/benchmarks/makeTxDB/makeTxDB.tsv"
    resources:
        mem_mb = 120000
    conda:
        "repeatanalysis"
    script:
        "scripts/txdbBSgenome.R"

rule get_transcriptome:
    input:
        gtf = "aref/{sample_or_ref}_annotations/{annot}.gtf",
        ref = "aref/A.REF.fa"
    output:
        fa = "aref/{sample_or_ref}_annotations/{annot}.fa"
    benchmark:
        "aref/benchmarks/get_transcriptome/{sample_or_ref}.{annot}.tsv"
    resources:
        mem_mb = 128000,
        runtime = 300
    conda:
        "omics"
    shell:
        """
agat_sp_extract_sequences.pl -g {input.gtf} -f {input.ref} -t exon --merge -o {output.fa}
        """

rule annotate_rtes:
    input:
        r_annotation_fragmentsjoined = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker.gtf.rformatted.fragmentsjoined.csv",
        ref = "aref/{sample_or_ref}.fa",
        txdbrefseq = "aref/A.REF_annotations/refseq.sqlite",
    output:
        r_repeatmasker_annotation = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_annotation.csv",
        rmann = "aref/{sample_or_ref}_annotations/{sample_or_ref}_rmann.csv",
        rmann_nonref = "aref/{sample_or_ref}_annotations/{sample_or_ref}_rmann_nonref.csv"
    benchmark:
        "aref/benchmarks/annotate_rtes/{sample_or_ref}.tsv"
    priority:
        100
    conda:
        "evo2"
    script:
        "scripts/annotate_rtes.R"

rule getRTEbeds:
    input:
        r_annotation_fragmentsjoined = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker.gtf.rformatted.fragmentsjoined.csv",
        r_repeatmasker_annotation = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_annotation.csv",
    output:
        outfile = "aref/{sample_or_ref}_annotations/{sample_or_ref}_rte_beds/outfile.txt"
    benchmark:
        "aref/benchmarks/getRTEbeds/{sample_or_ref}.tsv"
    conda:
        "evo2"
    script:
        "scripts/getRTEbeds.R"

rule element_analysis:
    input:
        r_annotation_fragmentsjoined = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker.gtf.rformatted.fragmentsjoined.csv",
        r_repeatmasker_annotation = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_annotation.csv",
        ref = "aref/{sample_or_ref}.fa"
    params:
        l13 = config["l13fasta"]
    output:
        plots = "aref/{sample_or_ref}_Analysis/l1element_analysis.rds"
    benchmark:
        "aref/benchmarks/element_analysis/{sample_or_ref}.tsv"
    conda:
        "evo2"
    script:
        "scripts/element_analysis.R"


rule make_star_index:
    input:
        reference = "aref/{sample_or_ref}.fa"
    output:
        outfile = "aref/{sample_or_ref}_indeces/make_star_index.out"
    benchmark:
        "aref/benchmarks/make_star_index/{sample_or_ref}.tsv"
    resources:
        cpus_per_task = 32,
        mem_mb = 128000,
        runtime = 300
    conda:
        "star"
    shell:
        """
mkdir -p $(dirname {output.outfile})
STAR --runThreadN  30 --runMode genomeGenerate --genomeDir $(dirname {output.outfile})/star_index --genomeFastaFiles {input.reference} --outTmpDir $(dirname {output.outfile})/tmp
touch {output.outfile}
        """

rule cpgIsland:
    params:
        ref_cpgislands = config["ref_cpgislands"]
    output:
        cpg_islands_fullinfo = "aref/A.REF_annotations/cpg_islands.tsv",
        cpg_islands = "aref/A.REF_annotations/cpg_islands.bed",
        cpgi_shores = "aref/A.REF_annotations/cpgi_shores.bed",
        cpgi_shelves = "aref/A.REF_annotations/cpgi_shelves.bed"
    benchmark:
        "aref/benchmarks/cpgIsland/cpgIsland.tsv"
    priority:
        100
    resources:
        cpus_per_task = 2,
        mem_mb = 20000,
        runtime = 60
    conda:
        "ds"
    script:
        "scripts/cpgIsland.R"

rule copySelectAnnotations:
    params:
        ref_cytobands = config["ref_cytobands"],
        ref_telomere = config["ref_telomere"],
    output:
        ref_cytobands = "aref/A.REF_annotations/cytobands.bed",
        ref_telomere = "aref/A.REF_annotations/telomeres.bed",
    benchmark:
        "aref/benchmarks/copySelectAnnotations/copySelectAnnotations.tsv"
    shell:
        """
cp {params.ref_cytobands} {output.ref_cytobands}
cp {params.ref_telomere} {output.ref_telomere}
        """


rule create_blast_db:
    input:
        ref = "aref/{sample_or_ref}.fa",
    output:
        outfile = "aref/{sample_or_ref}.blastdb_outfile"
    benchmark:
        "aref/benchmarks/create_blast_db/{sample_or_ref}.tsv"
    conda:
        "evo2"
    shell:
        """
makeblastdb -in {input.ref} -dbtype nucl -out aref/{wildcards.sample_or_ref}
touch {output.outfile}
        """

rule transduction_mapping:
    input:
        filtered_tldr = "aref/{sample_or_ref}_tldr/{sample_or_ref}.table.kept_in_updated_ref.txt",
        unfiltered_tldr = "aref/{sample_or_ref}_tldr/{sample_or_ref}.table.txt",
        r_annotation_fragmentsjoined = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker.gtf.rformatted.fragmentsjoined.csv",
        r_repeatmasker_annotation = "aref/{sample_or_ref}_annotations/{sample_or_ref}_repeatmasker_annotation.csv",
        ref = "aref/{sample_or_ref}.fa",
        blast_njs = "aref/{sample_or_ref}.blastdb_outfile",
        element_analysis = "aref/{sample_or_ref}_Analysis/l1element_analysis.rds"
    params:
        sample_or_ref = lambda w: w.sample_or_ref
    output:
        plots = "aref/{sample_or_ref}_Analysis/tldr_plots/transduction_mapping.rds",
        # circlize_phylogeny = "aref/{sample_or_ref}_Analysis/tldr_plots/circlize_phylogeny.png",
        # circlize_transduction = "aref/{sample_or_ref}_Analysis/tldr_plots/circlize_transduction.png",
        # transduction_df = "aref/{sample_or_ref}_Analysis/transduction_df.csv"
    benchmark:
        "aref/benchmarks/transduction_mapping/{sample_or_ref}.tsv"
    conda:
        "evo2"
    script:
        "scripts/transduction_mapping.R"


rule setup_protein_blast_db:
    output:
        outfile = "aref/blastdb/pdbaa/outfile.out"
    benchmark:
        "aref/benchmarks/setup_protein_blast_db/setup_protein_blast_db.tsv"
    conda:
        "blast"
    shell:
        """
mkdir -p $(dirname {output.outfile})
cd $(dirname {output.outfile})
update_blastdb.pl --decompress pdbaa
touch outfile.out
        """